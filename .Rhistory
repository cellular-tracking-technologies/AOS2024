x <- tbl(con, "nodes") %>% dplyr::pull(node_id)
x
devtools::update_packages("celltracktech")
e <- "/home/jess/Documents/work/data/CTT/CTT Office/V30B0154DA76/raw/CTT-V30B0154DA76-raw-data.2022-12-20_142728.csv.gz"
filetype <- "raw"
#print(filetype)
file_err <- 0
myrowfix <- c()
ignore <- FALSE
contents <- tryCatch(
{
readr::read_csv(e, col_names = TRUE)
},
error = function(err) {
return(NULL)
}
)
head(contents)
if (filetype == "raw" & ncol(contents) > 6) {
contents <- contents[,1:6]
ignore <- TRUE
}
contents
contents <- file_handle(e, filetype)[[1]]
contents
e
contents <- db_prep(contents, filetype, sensor, y, begin)
contents
sensor
y <- e
begom
begin
source("~/Documents/work/code/CTT/celltracktech/R/api_postgres.R")
i <- DBI::dbReadTable(conn, "ctt_project_station")
#conn <- dbConnect(RPostgres::Postgres(), dbname=db_name)
con <- dbConnect(duckdb(), dbdir = "/home/jess/Documents/work/data/CTT/my-db.duckdb", read_only = FALSE)
begin <- i[i$station_id == sensor, ]$deploy_at
if (length(begin) == 0) {
begin <- as.POSIXct("2018-01-01")
}
i <- DBI::dbReadTable(conn, "ctt_project_station")
begin <- i[i$station_id == sensor, ]$deploy_at
if (length(begin) == 0) {
begin <- as.POSIXct("2018-01-01")
}
begin
i
e <- "/home/jess/Documents/work/data/CTT/CTT Office/V30B0154DA76/node_health/CTT-V30B0154DA76-node-health.2022-07-23_195742.csv.gz"
filetype <- "node_health"
sensor
out <- get_file_info(e)
filetype <- out$filetype
sensor <- out$sensor
y <- out$y
i <- DBI::dbReadTable(conn, "ctt_project_station")
sensor
begin
# print("attempting import")
outtest <- file_handle(e, filetype)
contents <- outtest[[1]]
errtype <- outtest[[2]]
contents
errtype
contents <- db_prep(contents, filetype, sensor, y, begin)
contents
contents$node_id <- toupper(contents$node_id)
nodeids <- contents$node_id[which(!is.na(contents$node_id))]
head(contents)
#conn <- dbConnect(RPostgres::Postgres(), dbname=db_name)
con <- dbConnect(duckdb(), dbdir = "/home/jess/Documents/work/data/CTT/my-db.duckdb", read_only = FALSE)
conn <- con
if (filetype %in% c("raw", "blu")) {
vars <- paste(DBI::dbListFields(conn, filetype)[2:length(DBI::dbListFields(conn, filetype))], sep = "", collapse = ",")
vals <- paste(seq_along(1:(length(DBI::dbListFields(conn, filetype)) - 1)), sep = "", collapse = ", $")
contents <- contents[, DBI::dbListFields(conn, filetype)[2:length(DBI::dbListFields(conn, filetype))]]
} else {
vars <- paste(DBI::dbListFields(conn, filetype), sep = "", collapse = ",")
vals <- paste(seq_along(1:length(DBI::dbListFields(conn, filetype))), sep = "", collapse = ", $")
names(contents) <- tolower(names(contents))
contents <- contents[, DBI::dbListFields(conn, filetype)]
}
contents
head(contents)
y
filetype
DBI::dbWriteTable(conn, filetype, contents, append = TRUE)
max(contents$radio_id)
max(contents$node_rssi)
max(contents$battery)
max(!is.na(contents$battery))
max(contents$battery), na.rm=T)
max(contents$battery, na.rm=T)
max(contents$celsius, na.rm=T)
max(contents$firmware, na.rm=T)
max(contents$solar_volts, na.rm=T)
max(contents$solar_current, na.rm=T)
max(contents$cumulative_solar_current, na.rm=T)
tail(contents$cumulative_solar_current)
contents[contents$cumulative_solar_current==3189130580,]
if (ncol(contents) < 9) {
contents$RecordedAt <- NA
contents$Firmware <- NA
contents$SolarVolts <- NA
contents$SolarCurrent <- NA
contents$CumulativeSolarCurrent <- NA
contents$Latitude <- NA
contents$Longitude <- NA
} else if(ncol(contents) > 9) {contents <- contents[contents$CumulativeSolarCurrent < 2147483647,]}
contents <- file_handle(e, filetype)[[1]]
contents <- db_prep(contents, filetype, sensor, y, begin)
contents
source("~/Documents/work/code/CTT/celltracktech/R/api_postgres.R")
contents <- file_handle(e, filetype)[[1]]
contents <- db_prep(contents, filetype, sensor, y, begin)
max(contents$cumulative_solar_current, na.rm=T)
#db_cleanup(conn)
dbDisconnect(con)
source("~/Documents/work/code/CTT/api_run_office.R")
source("~/Documents/work/code/CTT/api_run_office.R")
datafiles <- tbl(con, "datafile") %>% dplyr::pull()
#conn <- dbConnect(RPostgres::Postgres(), dbname=db_name)
con <- dbConnect(duckdb(), dbdir = "/home/jess/Documents/work/data/CTT/my-db.duckdb", read_only = FALSE)
datafiles <- tbl(con, "datafile") %>% dplyr::pull()
dbListTables(con)
datafiles <- tbl(con, "data_file") %>% dplyr::pull()
datafiles
e <- "CTT-V30B0154DA76-node-health.2022-07-23_195742.csv.gz"
e
head(datafiles)
e %in% datafiles
#db_cleanup(conn)
dbDisconnect(con)
source("~/Documents/work/code/CTT/celltracktech/R/api_postgres.R")
source("~/Documents/work/code/CTT/api_run_office.R")
e <- "/home/jess/Documents/work/data/CTT/CTT Office/V30B0154DA76/node_health/CTT-V30B0154DA76-node-health.2022-07-11_054654.csv.gz"
filetype <- "node_health"
sensor
begin
contents <- file_handle(e, filetype)[[1]]
contents
contents <- db_prep(contents, filetype, sensor, y, begin)
contents
contents$node_id <- toupper(contents$node_id)
vars <- paste(DBI::dbListFields(conn, filetype), sep = "", collapse = ",")
vals <- paste(seq_along(1:length(DBI::dbListFields(conn, filetype))), sep = "", collapse = ", $")
names(contents) <- tolower(names(contents))
#conn <- dbConnect(RPostgres::Postgres(), dbname=db_name)
con <- dbConnect(duckdb(), dbdir = "/home/jess/Documents/work/data/CTT/my-db.duckdb", read_only = FALSE)
conn <- con
vars <- paste(DBI::dbListFields(conn, filetype), sep = "", collapse = ",")
vals <- paste(seq_along(1:length(DBI::dbListFields(conn, filetype))), sep = "", collapse = ", $")
names(contents) <- tolower(names(contents))
contents <- contents[, DBI::dbListFields(conn, filetype)]
contents
head(contents)
DBI::dbWriteTable(conn, filetype, contents, append = TRUE)
max(contents$cumulative_solar_current, na.rm=T)
max(contents$latitude, na.rm=T)
contents[contents$latitude == 536.9733,]
contents[contents$latitude > 536,]
contents <- file_handle(e, filetype)[[1]]
row.names(contents)
timecols <- c("Time") # , "recorded at", "gps at", "RecordedAt", "recorded.at", "gps.at")
for (x in timecols) {
if (x %in% names(contents)) {
contents <- dplyr::filter(contents, (!!as.name(x)) < Sys.time() & (!!as.name(x)) > begin)
}
}
contents <- data.frame(contents)
row.names(contents)
contents$station_id <- sensor
contents$path <- y
contents$Battery[which(contents$Battery > 9)] <- NA
contents1 <- contents[contents$Latitude < 90,]
row.names(contents1)
contents1 <- contents[which(contents$Latitude < 90),]
row.names(contents1)
nodecheck <- contents[which(!is.na(contents$node_id)), ]
source("~/Documents/work/code/CTT/celltracktech/R/api_postgres.R")
source("~/Documents/work/code/CTT/api_run_office.R")
e
source("~/Documents/work/code/CTT/api_run_office.R")
all(is.na(contents[,2]))
contents[,2]
e <- "/home/jess/Documents/work/data/CTT/CTT Office/V30B0154DA76/gps/CTT-V30B0154DA76-gps.2022-06-23_130630.csv.gz"
filetype <- "gps"
contents <- file_handle(e, filetype)#[[1]]
contents[[1]]
contents[[2]]
contents <- contents[which(!is.na(contents$latitude)),]
contents <- contents[[1]]
contents <- contents[which(!is.na(contents$latitude)),]
contents
source("~/Documents/work/code/CTT/celltracktech/R/api_postgres.R")
#db_cleanup(conn)
dbDisconnect(con)
source("~/Documents/work/code/CTT/api_run_office.R")
source("~/Documents/work/code/CTT/api_run_office.R")
e <- "/home/jess/Documents/work/data/CTT/CTT Office/V30B0154D154/raw/CTT-V30B0154D154-raw-data.2024-09-12_230037.csv.gz"
filetype <- "raw"
contents <- file_handle(e, filetype)[[1]]
out <- get_file_info(e)
filetype <- out$filetype
sensor <- out$sensor
y <- out$y
i <- DBI::dbReadTable(conn, "ctt_project_station")
begin <- i[i$station_id == sensor, ]$deploy_at
if (length(begin) == 0) {
begin <- as.POSIXct("2018-01-01")
}
# print("attempting import")
outtest <- file_handle(e, filetype)
contents <- outtest[[1]]
errtype <- outtest[[2]]
contents <- db_prep(contents, filetype, sensor, y, begin)
contents
# print("attempting import")
outtest <- file_handle(e, filetype)
contents <- outtest[[1]]
contents
contents <- db_prep(contents, filetype, sensor, y, begin)
contents
nrow(contents)
contents <- tryCatch(
{
readr::read_csv(e, col_names = TRUE)
},
error = function(err) {
return(NULL)
}
)
contents
source("~/Documents/work/code/CTT/celltracktech/R/api_postgres.R")
#db_cleanup(conn)
dbDisconnect(con)
source("~/Documents/work/code/CTT/api_run_office.R")
source("~/Documents/work/code/CTT/api_run_office.R")
source("~/Documents/work/code/CTT/celltracktech/R/api_postgres.R")
source("~/Documents/work/code/CTT/api_run_office.R")
source("~/Documents/work/code/CTT/api_run_office.R")
e <- "/home/jess/Documents/work/data/CTT/CTT Office/V30B0154B577/node_health/CTT-V30B0154B577-node-health.2024-08-25_210325.csv.gz"
filetype <- "node_health"
contents <- file_handle(e, filetype)[[1]]
contents
contents <- db_prep(contents, filetype, sensor, y, begin)
contents
head(contents)
sensor
begin
e
out <- get_file_info(e)
filetype <- out$filetype
sensor <- out$sensor
y <- out$y
i <- DBI::dbReadTable(conn, "ctt_project_station")
begin <- i[i$station_id == sensor, ]$deploy_at
if (length(begin) == 0) {
begin <- as.POSIXct("2018-01-01")
}
# print("attempting import")
outtest <- file_handle(e, filetype)
contents <- outtest[[1]]
errtype <- outtest[[2]]
contents <- db_prep(contents, filetype, sensor, y, begin)
if(nrow(contents) < 1) {errtype <- 7}
errtype
if(any(colnames(contents) == "node_id")) {
contents$node_id <- toupper(contents$node_id)
if (length(which(!is.na(contents$node_id))) > 0) {
nodeids <- contents$node_id[which(!is.na(contents$node_id))]
insertnew <- DBI::dbSendQuery(conn, paste("INSERT INTO ", "nodes (node_id)", " VALUES ($1)
ON CONFLICT DO NOTHING", sep = ""))
DBI::dbBind(insertnew, params = list(unique(nodeids)))
DBI::dbClearResult(insertnew)
}
} else {
nodeids <- c()
}
head(contents)
vars <- paste(DBI::dbListFields(conn, filetype), sep = "", collapse = ",")
vals <- paste(seq_along(1:length(DBI::dbListFields(conn, filetype))), sep = "", collapse = ", $")
names(contents) <- tolower(names(contents))
contents <- contents[, DBI::dbListFields(conn, filetype)]
DBI::dbWriteTable(conn, filetype, contents, append = TRUE)
max(contents$longitude, na.rm=T)
max(contents$uptime, na.rm=T)
contents$uptime == -Inf
which(contents$uptime == -Inf)
head(contents[order(contents$uptime),])
head(contents[order(contents$up_time),])
order(contents$up_time)
contents$up_time
contents
max(contents$radio_id, na.rm=T)
e
max(contents$node_rssi, na.rm=T)
max(contents$battery, na.rm=T)
max(contents$celsius, na.rm=T)
source("~/Documents/work/code/CTT/celltracktech/R/api_postgres.R")
source("~/Documents/work/code/CTT/api_run_office.R")
source("~/Documents/work/code/CTT/api_run_office.R")
devtools::update_packages("celltracktech")
source("~/Documents/work/code/CTT/api_run_office.R")
source("~/Documents/work/code/CTT/AOS2024/workshop_API.R")
devtools::update_packages("celltracktech")
source("~/Documents/work/code/CTT/AOS2024/workshop_API.R")
library(celltracktech)
################
get_my_data(my_token, outpath, con, myproject=myproject, begin=as.Date("2023-07-31"), end=as.Date("2023-10-31"), filetypes=c("raw", "node_health"))
library(celltracktech)
library(duckdb)
start <- Sys.time()
####SETTINGS#####
myproject <- "Meadows V2" #this is your project name on your CTT account
outpath <- "~/Documents/workshop" #where your downloaded files are to go
my_token <- "c2ed5f935e9b9d4c2e031f8a96277317b7502d989add5947656dbfbeee7082c5"
con <- DBI::dbConnect(duckdb::duckdb(), dbdir = "/home/jess/Documents/workshop/meadows.duckdb", read_only = FALSE)
################
get_my_data(my_token, outpath, con, myproject=myproject, begin=as.Date("2023-07-31"), end=as.Date("2023-10-31"), filetypes=c("raw", "node_health"))
library(celltracktech)
library(duckdb)
con <- DBI::dbConnect(duckdb::duckdb(), dbdir = "/home/jess/Documents/workshop/meadows.duckdb", read_only = FALSE)
con
my_token
outpath
db_name <- con
my_project
myproject
begin=as.Date("2023-07-31")
end=as.Date("2023-10-31")
filetypes=c("raw", "node_health"
)
projects <- project_list(my_token, myproject)
source("~/Documents/work/code/CTT/celltracktech/R/api_postgres.R")
projects <- project_list(my_token, myproject)
!is.null(db_name)
length(grep("duckdb", format(db_name))) > 0
create_duck(db_name)
db_name
sapply(projects, pop_proj, conn = db_name)
failed <- lapply(projects, get_data, f = db_name, outpath = outpath, my_station = mystation, beginning = begin, ending = end)
mystation = NULL
failed <- lapply(projects, get_data, f = db_name, outpath = outpath, my_station = mystation, beginning = begin, ending = end)
#' @param my_token your API key
#' @param outpath where your files are to be downloaded
#' @param db_name (optional) the connection to your local database
#' @param myproject the name of your project on our system
#' @param mystation (optional) the station ID you'd like to download data from
#' @param begin (optional) limit your data download to a start time
#' @param end (optional) limit your data download to an end time
#' @export
#' @examples
#' get_my_data(token, "~/mydata", myproject = "Project Name from CTT Account")
get_my_data <- function(my_token, outpath, db_name = NULL, myproject = NULL, mystation = NULL, begin = NULL, end = NULL, filetypes=NULL) {
projects <- project_list(my_token, myproject)
if (!is.null(db_name) & length(grep("postgresql", format(db_name))) > 0) {
create_db(db_name) # EDIT TO TAKE NEW create_db() when you switch back!
sapply(projects, pop_proj, conn = db_name)
failed <- lapply(projects, get_data, f = db_name, outpath = outpath, my_station = mystation, beginning = begin, ending = end)
} else if(!is.null(db_name) & length(grep("duckdb", format(db_name))) > 0) {
create_duck(db_name)
failed <- lapply(projects, get_data, f = db_name, outpath = outpath, my_station = mystation, beginning = begin, ending = end, filetypes=filetypes)
sapply(projects, pop_proj, conn = db_name)
} else {
failed <- lapply(projects, get_data, outpath = outpath, my_station = mystation, beginning = begin, ending = end)
}
faul <- which(!sapply(failed[[1]], is.null))
if (length(faul > 0)) {
failed <- Map(`[`, failed, faul)
save(failed, file = file.path(outpath, "caught.RData"))
} else {
failed <- "all good!"
save(failed, file = file.path(outpath, "caught.RData"))
}
}
################
get_my_data(my_token, outpath, con, myproject=myproject, begin=as.Date("2023-07-31"), end=as.Date("2023-10-31"), filetypes=c("raw", "node_health"))
library(celltracktech)
library(celltracktech)
library(duckdb)
start <- Sys.time()
####SETTINGS#####
myproject <- "Meadows V2" #this is your project name on your CTT account
outpath <- "~/Documents/workshop" #where your downloaded files are to go
my_token <- "c2ed5f935e9b9d4c2e031f8a96277317b7502d989add5947656dbfbeee7082c5"
con <- DBI::dbConnect(duckdb::duckdb(), dbdir = "/home/jess/Documents/workshop/meadows.duckdb", read_only = FALSE)
################
get_my_data(my_token, outpath, con, myproject=myproject, begin=as.Date("2023-07-31"), end=as.Date("2023-10-31"), filetypes=c("raw", "node_health"))
raw <- tbl(con, "data_file") |> collect()
raw
DBI::dbDisconnect(con)
source("~/Documents/work/code/CTT/AOS2024/workshop_API.R")
source("~/Documents/work/code/CTT/celltracktech/R/api_postgres.R")
projects <- project_list(my_token, myproject)
thisproject <- projects[[2]]
thisproject <- projects$projects[[2]]
thisproject
thisproject <- projects$projects
thisproject
projects
thisproject <- projects
# print("getting your file list")
projbasename <- thisproject$name
projbasename
thisproject <- projects[[1]]
# print("getting your file list")
projbasename <- thisproject$name
projbasename
id <- thisproject[["id"]]
myfiles <- list.files(file.path(outpath), recursive = TRUE)
dir.create(file.path(outpath, projbasename), showWarnings = FALSE)
files_loc <- sapply(strsplit(myfiles, "/"), tail, n = 1)
my_stations <- getStations(project_id = id)
if (!is.null(my_station)) {
my_stations[["stations"]] <- list(my_stations[[1]][[which(sapply(my_stations[[1]], function(x) x[["station"]][["id"]] == my_station))]])
}
my_stations
id
my_stations[["stations"]] <- list(my_stations[[1]][[which(sapply(my_stations[[1]], function(x) x[["station"]][["id"]] == my_station))]])
my_station <- NULL
if (!is.null(my_station)) {
my_stations[["stations"]] <- list(my_stations[[1]][[which(sapply(my_stations[[1]], function(x) x[["station"]][["id"]] == my_station))]])
}
files_avail <- lapply(my_stations[["stations"]], function(station, mybeginning = beginning, myending = ending) {
print(station)
if (is.null(mybeginning)) {
beginning <- as.POSIXct(station[["deploy-at"]], format = "%Y-%m-%dT%H:%M:%OS", tz = "UTC", optional = TRUE)
} else {
beginning <- as.POSIXct(as.Date(mybeginning), format = "%Y-%m-%dT%H:%M:%OS", tz = "UTC", optional = TRUE)
}
kwargs <- list(
station_id = station[["station"]][["id"]],
begin = beginning
)
print(is.null(myending))
if (!is.null(myending)) {
kwargs[["end"]] <- as.POSIXct(as.Date(myending), format = "%Y-%m-%dT%H:%M:%OS", tz = "UTC", optional = TRUE)
} else if (!is.null(station[["end-at"]])) {
kwargs[["end"]] <- as.POSIXct(station[["end-at"]], format = "%Y-%m-%dT%H:%M:%OS", tz = "UTC", optional = TRUE)
}
print(kwargs)
# print("getting station file list...")
file_info <- do.call(getStationFileList, kwargs)
outfiles <- file_info[["files"]]
# print(outfiles)
# print(paste(length(outfiles), "files available"))
return(outfiles)
})
begin=as.Date("2023-07-31")
end=as.Date("2023-10-31")
beginning <- beginn
beginning <- begin
ending <- end
files_avail <- lapply(my_stations[["stations"]], function(station, mybeginning = beginning, myending = ending) {
print(station)
if (is.null(mybeginning)) {
beginning <- as.POSIXct(station[["deploy-at"]], format = "%Y-%m-%dT%H:%M:%OS", tz = "UTC", optional = TRUE)
} else {
beginning <- as.POSIXct(as.Date(mybeginning), format = "%Y-%m-%dT%H:%M:%OS", tz = "UTC", optional = TRUE)
}
kwargs <- list(
station_id = station[["station"]][["id"]],
begin = beginning
)
print(is.null(myending))
if (!is.null(myending)) {
kwargs[["end"]] <- as.POSIXct(as.Date(myending), format = "%Y-%m-%dT%H:%M:%OS", tz = "UTC", optional = TRUE)
} else if (!is.null(station[["end-at"]])) {
kwargs[["end"]] <- as.POSIXct(station[["end-at"]], format = "%Y-%m-%dT%H:%M:%OS", tz = "UTC", optional = TRUE)
}
print(kwargs)
# print("getting station file list...")
file_info <- do.call(getStationFileList, kwargs)
outfiles <- file_info[["files"]]
# print(outfiles)
# print(paste(length(outfiles), "files available"))
return(outfiles)
})
filenames <- unname(rapply(files_avail, grep, pattern = "CTT", value = TRUE))
files_to <- filenames[!filenames %in% files_loc]
files_to
filenames
allfiles <- rapply(files_avail, function(z) z %in% files_to, how = "unlist") # this is the super intensive, time consuming function...
ids <- unlist(files_avail)[which(allfiles) - 1]
file_names <- unlist(files_avail)[which(allfiles)]
if (is.null(filetypes)) {filetypes <- c("raw", "node_health", "gps", "blu")}
filetypes=c("raw", "node_health")
if (is.null(filetypes)) {filetypes <- c("raw", "node_health", "gps", "blu")}
filetypes
ids
filenames
filesget <- data.frame(ids, file_names)
filesget
head(filesget)
sapply(file_names, function(x) get_file_info(x)["filetype"])
unlist(sapply(file_names, function(x) get_file_info(x)["filetype"]))
filetypeget <- unlist(sapply(file_names, function(x) get_file_info(x)["filetype"]))
filesget <- data.frame(ids, file_names, filetypeget)
head(filesget)
tail(filesget)
devtools::update_packages()
setwd("~/Documents/work/code/CTT/AOS2024")
library(duckdb)
con <- dbConnect(duckdb())
test <- tbl(con, "calibration_all.csv") |>
#filter(RSSI > -40) |>
collect()
library(dplyr)
test <- tbl(con, "calibration_all.csv") |>
#filter(RSSI > -40) |>
collect()
test
